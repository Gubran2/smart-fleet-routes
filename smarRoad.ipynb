{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b70f00c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: folium>=0.12 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.17.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.4)\n",
      "Collecting mapclassify\n",
      "  Downloading mapclassify-2.10.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: branca>=0.6.0 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from folium>=0.12) (0.8.2)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from folium>=0.12) (3.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from folium>=0.12) (1.26.4)\n",
      "Requirement already satisfied: requests in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from folium>=0.12) (2.32.3)\n",
      "Requirement already satisfied: xyzservices in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from folium>=0.12) (2025.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: networkx>=3.2 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mapclassify) (3.2.1)\n",
      "Requirement already satisfied: pandas>=2.1 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mapclassify) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.4 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mapclassify) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.12 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mapclassify) (1.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2>=2.9->folium>=0.12) (2.1.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=2.1->mapclassify) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=2.1->mapclassify) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=1.4->mapclassify) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=1.4->mapclassify) (3.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->folium>=0.12) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->folium>=0.12) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->folium>=0.12) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gubra\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->folium>=0.12) (2024.6.2)\n",
      "Downloading mapclassify-2.10.0-py3-none-any.whl (882 kB)\n",
      "   ---------------------------------------- 0.0/882.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 882.2/882.2 kB 13.2 MB/s eta 0:00:00\n",
      "Installing collected packages: mapclassify\n",
      "Successfully installed mapclassify-2.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install \"folium>=0.12\" matplotlib mapclassify\n",
    "# Ø£Ùˆ conda:\n",
    "# conda install -c conda-forge \"folium>=0.12\" matplotlib mapclassify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c343afcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¡ Loading road network BBOX...\n",
      "â„¹ï¸ Nodes/Edges in largest CC: 865 / 2330\n",
      "âœ… Generated on-road points: 550\n",
      "ğŸ”§ After clustering within 15 m: 550 points\n",
      "âœ… Points after mapping to unique reachable nodes: 364\n",
      "ğŸ” Depot candidates (node:reach,sum_s): 729765259:358,55584, 720711536:358,53286, 738481067:358,53147, 729716900:358,54110, 1351945438:358,53878, 1069557692:358,52391, 12422199136:358,76139, 729688549:358,83735, 3191439065:358,85412, 1069557685:358,71151, 12422199126:358,110199, 715884170:358,54723, 719653758:358,72432, 1069689543:358,74192, 4178558136:358,115695, 705902002:358,55221\n",
      "âœ… Picked depot node: 1069557692  (directed reach 358/364)\n",
      "\n",
      "=== Results ===\n",
      "ğŸšš Vehicle  1: 178 stops | travel=122.6m | service=269.7m | total=392.3m | dist=59.40 km\n",
      "ğŸšš Vehicle  2: 186 stops | travel=142.6m | service=281.6m | total=424.2m | dist=67.32 km\n",
      "\n",
      "Coverage: 364/364 points reached\n",
      "Total time (all): 13.6 hours\n",
      "Longest vehicle: 7.1 hours\n",
      "ğŸ—ºï¸ Saved interactive map: vrp_map.html\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ==========================================\n",
    "#  VRP Ø¹Ù„Ù‰ Ø´Ø¨ÙƒØ© Ø·Ø±Ù‚ OSMnx (v2-ready)\n",
    "#  - Ø¨Ù†Ø§Ø¡ Ø´Ø¨ÙƒØ© Ù…Ù† BBOX\n",
    "#  - Ø³Ø±Ø¹Ø§Øª Ù…Ø®ØµØµØ© + travel_time\n",
    "#  - ØªÙˆÙ„ÙŠØ¯ Ù†Ù‚Ø§Ø· \"Ø¹Ù„Ù‰ Ø§Ù„Ø·Ø±ÙŠÙ‚\" Ù…ÙˆØ²ÙˆÙ†Ø© Ø¨Ø·ÙˆÙ„ Ø§Ù„Ø­ÙˆØ§Ù\n",
    "#  - Ø§Ø®ØªÙŠØ§Ø± Ø¯ÙŠØ¨Ùˆ Ø°ÙƒÙŠ ÙŠØ²ÙŠØ¯ Ø§Ù„ÙˆØµÙˆÙ„ Ø§Ù„Ù…ÙˆØ¬Ù‘Ù‡\n",
    "#  - ØªÙ‚Ø³ÙŠÙ… Sweep + NN + 2-opt\n",
    "#  - Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª + Ø®Ø±ÙŠØ·Ø© ØªÙØ§Ø¹Ù„ÙŠØ© (GeoPandas.explore)\n",
    "# ==========================================\n",
    "\n",
    "import math, random, functools, time, warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "from shapely.geometry import box, LineString, Point\n",
    "\n",
    "# Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… GeoPandas + folium Ù„Ø¹Ù…Ù„ Ø®Ø±ÙŠØ·Ø© ØªÙØ§Ø¹Ù„ÙŠØ©\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "    _HAS_GPD = True\n",
    "except Exception:\n",
    "    _HAS_GPD = False\n",
    "\n",
    "try:\n",
    "    import folium\n",
    "    _HAS_FOLIUM = True\n",
    "except Exception:\n",
    "    _HAS_FOLIUM = False\n",
    "\n",
    "# ------------------------------------------\n",
    "# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ø§Ù…Ø© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„\n",
    "# ------------------------------------------\n",
    "# ØµÙ†Ø¯ÙˆÙ‚ Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù… (minx=west, miny=south, maxx=east, maxy=north) Ø¨ÙˆØ­Ø¯Ø§Øª lon/lat\n",
    "WEST, SOUTH, EAST, NORTH = 36.71519, 34.00945, 36.74922, 34.03680\n",
    "POLY = box(WEST, SOUTH, EAST, NORTH)\n",
    "\n",
    "# Ù…Ø±ÙƒØ¨Ø§ØªØŒ Ù†Ù‚Ø§Ø·ØŒ Ù…Ø³Ø§ÙØ§ØªØŒ ØªØ­Ø³ÙŠÙ†\n",
    "V = 2                       # Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø±ÙƒØ¨Ø§Øª\n",
    "POINTS_N = 550              # Ø¹Ø¯Ø¯ Ù†Ù‚Ø§Ø· Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø±Ø§Ø¯ ØªÙˆÙ„ÙŠØ¯Ù‡Ø§\n",
    "MIN_SPACING_M = 80          # Ù…Ø³Ø§ÙØ© Ø¯Ù†ÙŠØ§ Ø¨ÙŠÙ† Ø§Ù„Ù†Ù‚Ø§Ø· ÙˆÙ‚Øª Ø§Ù„ØªÙˆÙ„ÙŠØ¯\n",
    "CLUSTER_RADIUS_M = 15       # Ø¯Ù…Ø¬ Ù†Ù‚Ø§Ø· Ù‚Ø±ÙŠØ¨Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)\n",
    "USE_2OPT = True\n",
    "MAX_2OPT_ITERS = 150\n",
    "\n",
    "# ØªØ³Ø±ÙŠØ¹/Ø¥Ø¨Ø·Ø§Ø¡ Ø£Ø²Ù…Ù†Ø© Ø§Ù„Ø³ÙØ± (Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„Ù‰ Ø¥Ø´Ø§Ø±Ø§Øª/ØªÙ‚Ø§Ø·Ø¹Ø§Øª..)\n",
    "CITY_TIME_FACTOR = 1.3\n",
    "\n",
    "# Ø£Ø²Ù…Ù†Ø© Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ù„ÙƒÙ„ Ù†Ù‚Ø·Ø© (Ø«ÙˆØ§Ù†ÙŠ)\n",
    "SERVICE_TIME_RANGE = (60, 120)\n",
    "\n",
    "# ØªØ«Ø¨ÙŠØª Ø§Ù„Ø¨Ø°ÙˆØ± Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
    "random.seed(42); np.random.seed(42)\n",
    "\n",
    "# Ø³Ø±Ø¹Ø§Øª Ù…Ø®ØµØµØ© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø·Ø±ÙŠÙ‚ (ÙƒÙ…/Ø³)\n",
    "CUSTOM_SPEEDS = {\n",
    "    \"motorway\":80, \"motorway_link\":60,\n",
    "    \"trunk\":70, \"trunk_link\":60,\n",
    "    \"primary\":60, \"primary_link\":50,\n",
    "    \"secondary\":50, \"secondary_link\":45,\n",
    "    \"tertiary\":40, \"tertiary_link\":35,\n",
    "    \"residential\":30, \"living_street\":20,\n",
    "    \"service\":20, \"unclassified\":35\n",
    "}\n",
    "\n",
    "# ------------------------------------------\n",
    "# Ø¨Ù†Ø§Ø¡ Ø´Ø¨ÙƒØ© Ø§Ù„Ø·Ø±Ù‚ Ù…Ø¹ travel_time (OSMnx v2)\n",
    "# ------------------------------------------\n",
    "print(\"ğŸ“¡ Loading road network BBOX...\")\n",
    "G = ox.graph_from_polygon(\n",
    "    POLY,\n",
    "    network_type=\"drive\",\n",
    "    retain_all=True,\n",
    "    simplify=True,\n",
    "    truncate_by_edge=True\n",
    ")\n",
    "\n",
    "# Ø£Ø¶Ù Ø§Ù„Ø³Ø±Ø¹Ø§Øª Ø«Ù… travel_time (v2: ØªØ­Øª osmnx.routing)\n",
    "# https://osmnx.readthedocs.io/en/stable/internals-reference.html#osmnx.routing.add_edge_speeds\n",
    "G = ox.routing.add_edge_speeds(G, hwy_speeds=CUSTOM_SPEEDS)\n",
    "G = ox.routing.add_edge_travel_times(G)\n",
    "\n",
    "# Ø¹Ø§Ù…Ù„ Ù…Ø¯ÙŠÙ†Ø© Ù„Ù„ÙˆØ§Ù‚Ø¹ÙŠØ©\n",
    "for _, _, _, d in G.edges(keys=True, data=True):\n",
    "    if \"travel_time\" in d:\n",
    "        d[\"travel_time\"] *= CITY_TIME_FACTOR\n",
    "\n",
    "# ØªØ£ÙƒØ¯ Ù…Ù† CRS = EPSG:4326 (lon/lat)\n",
    "G = ox.project_graph(G, to_crs=\"EPSG:4326\")\n",
    "\n",
    "# Ø®Ø° Ø£ÙƒØ¨Ø± Ù…ÙƒÙˆÙ‘Ù† Ø¶Ø¹ÙŠÙ Ø§Ù„Ø§ØªØµØ§Ù„ (weakly) Ø­ØªÙ‰ Ù„Ø§ Ù†ØªÙ‚ÙŠÙ‘Ø¯ Ø¨Ù†Ù‚Ø·Ø© Ø¯ÙŠØ¨Ùˆ Ù…Ø³Ø¨Ù‚Ø©\n",
    "# https://osmnx.readthedocs.io/en/stable/internals-reference.html#osmnx.truncate.largest_component\n",
    "G_cc = ox.truncate.largest_component(G, strongly=False)\n",
    "\n",
    "Gud = G_cc.to_undirected(as_view=True)  # Ù†Ø³Ø®Ø© ØºÙŠØ± Ù…ÙˆØ¬Ù‘Ù‡Ø© Ù„Ù„Ø§Ø­ØªÙŠØ§Ø·\n",
    "print(f\"â„¹ï¸ Nodes/Edges in largest CC: {G_cc.number_of_nodes()} / {G_cc.number_of_edges()}\")\n",
    "\n",
    "# ØªÙ‚Ø¯ÙŠØ± Ø³Ø±Ø¹Ø© fallback (Ù…/Ø«) Ù„Ù„Ø§Ø­ØªÙŠØ§Ø· ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬Ù‘Ù‡\n",
    "speeds_kph = []\n",
    "for _, _, _, d in G_cc.edges(keys=True, data=True):\n",
    "    sp = d.get(\"speed_kph\", np.nan)\n",
    "    if sp is not None:\n",
    "        speeds_kph.append(sp)\n",
    "fallback_mps = (np.nanmedian(speeds_kph) if len(speeds_kph) else 30.0) * 1000/3600.0\n",
    "\n",
    "# ------------------------------------------\n",
    "# ØªÙˆÙ„ÙŠØ¯ Ù†Ù‚Ø§Ø· \"Ø¹Ù„Ù‰ Ø§Ù„Ø·Ø±ÙŠÙ‚\" Ù…ÙˆØ²ÙˆÙ†Ø© Ø¨Ø·ÙˆÙ„ Ø§Ù„Ø­ÙˆØ§Ù\n",
    "# ------------------------------------------\n",
    "# Ø³Ù†Ø³ØªØ®Ø¯Ù… ÙˆØ²Ù† Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ = Ø·ÙˆÙ„ Ø§Ù„Ø­Ø§ÙØ© Ø¨Ø§Ù„Ù…ØªØ± (d[\"length\"])\n",
    "edges_for_sampling = []\n",
    "cum = []\n",
    "tot_m = 0.0\n",
    "for u, v, k, d in G_cc.edges(keys=True, data=True):\n",
    "    Lm = float(d.get(\"length\", 0.0))  # Ù…ØªØ±\n",
    "    if Lm <= 0:\n",
    "        continue\n",
    "    geom = d.get(\"geometry\")\n",
    "    if geom is None:\n",
    "        # Ø£Ù†Ø´Ø¦ Ø®Ø·Ù‹Ø§ Ù…Ø³ØªÙ‚ÙŠÙ…Ù‹Ø§ Ø¨ÙŠÙ† Ø§Ù„Ø¹Ù‚Ø¯ØªÙŠÙ† (Ø¨Ø§Ù„Ø¯Ø±Ø¬Ø§ØªØŒ Ù„ÙƒÙ† Ø³Ù†Ø³ØªØ®Ø¯Ù… Ù†Ø³Ø¨Ø© t ÙÙ‚Ø·)\n",
    "        geom = LineString([(G_cc.nodes[u][\"x\"], G_cc.nodes[u][\"y\"]),\n",
    "                           (G_cc.nodes[v][\"x\"], G_cc.nodes[v][\"y\"])])\n",
    "    edges_for_sampling.append((u, v, k, geom, Lm))\n",
    "    tot_m += Lm\n",
    "    cum.append(tot_m)\n",
    "\n",
    "def _sample_edge_by_length():\n",
    "    # Ø§Ø®ØªÙŠØ§Ø± Ø­Ø§ÙØ© Ø¨ÙˆØ²Ù† Ø§Ù„Ø·ÙˆÙ„ (Ù…ØªØ±)\n",
    "    r = random.random() * tot_m\n",
    "    idx = next(i for i, c in enumerate(cum) if c >= r)\n",
    "    return edges_for_sampling[idx]\n",
    "\n",
    "def sample_point_on_edge():\n",
    "    u, v, k, geom, Lm = _sample_edge_by_length()\n",
    "    # Ø§Ø®ØªØ± Ù…ÙˆØ¶Ø¹Ù‹Ø§ ÙƒÙ†Ø³Ø¨Ø© t Ø¹Ù„Ù‰ Ø§Ù„Ù‡Ù†Ø¯Ø³Ø© (Ø§Ù„ÙˆØ­Ø¯Ø© Ø¯Ø±Ø¬Ø§ØªØŒ Ù„ÙƒÙ† t Ù†Ø³Ø¨Ø©)\n",
    "    t = random.random()\n",
    "    p = geom.interpolate(t * geom.length)  # param Ø¨ÙˆØ­Ø¯Ø§Øª degreesØŒ t ÙŠØ¶Ù…Ù† ØªÙ†Ø§Ø³Ø¨\n",
    "    return (p.y, p.x)  # (lat, lon)\n",
    "\n",
    "def haversine_m(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000.0\n",
    "    p1, p2 = math.radians(lat1), math.radians(lat2)\n",
    "    dphi = math.radians(lat2 - lat1)\n",
    "    dlmb = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dphi/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(dlmb/2)**2\n",
    "    return 2*R*math.asin(math.sqrt(a))\n",
    "\n",
    "def generate_bin_points(n_points=POINTS_N, min_gap_m=MIN_SPACING_M, max_tries=10000):\n",
    "    pts = []\n",
    "    tries = 0\n",
    "    while len(pts) < n_points and tries < max_tries:\n",
    "        lat, lon = sample_point_on_edge()\n",
    "        ok = True\n",
    "        for (la, lo) in pts:\n",
    "            if haversine_m(lat, lon, la, lo) < min_gap_m:\n",
    "                ok = False\n",
    "                break\n",
    "        if ok:\n",
    "            pts.append((lat, lon))\n",
    "        tries += 1\n",
    "    return pts\n",
    "\n",
    "snapped_pts = generate_bin_points(POINTS_N, MIN_SPACING_M)\n",
    "print(f\"âœ… Generated on-road points: {len(snapped_pts)}\")\n",
    "\n",
    "# Ø§Ø®ØªÙŠØ§Ø±ÙŠ: Ø¯Ù…Ø¬ Ù†Ù‚Ø§Ø· Ù…ØªÙ‚Ø§Ø±Ø¨Ø© Ø¬Ø¯Ù‹Ø§ Ø¹Ø¨Ø± BallTree Ù„Ùˆ Ù…ØªØ§Ø­ sklearn\n",
    "try:\n",
    "    from sklearn.neighbors import BallTree\n",
    "    R_earth = 6371000.0\n",
    "    pts_rad = np.radians(np.array(snapped_pts))\n",
    "    tree = BallTree(pts_rad, metric='haversine')\n",
    "    picked = np.zeros(len(snapped_pts), dtype=bool)\n",
    "    clustered = []\n",
    "    for i in range(len(snapped_pts)):\n",
    "        if picked[i]: continue\n",
    "        idxs = tree.query_radius(pts_rad[i:i+1], r=CLUSTER_RADIUS_M/R_earth)[0]\n",
    "        clustered.append(snapped_pts[i])\n",
    "        picked[idxs] = True\n",
    "    snapped_pts = clustered\n",
    "    print(f\"ğŸ”§ After clustering within {CLUSTER_RADIUS_M} m: {len(snapped_pts)} points\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Ø­ÙˆÙ‘Ù„ ÙƒÙ„ Ù†Ù‚Ø·Ø© Ø¥Ù„Ù‰ Ø£Ù‚Ø±Ø¨ Ø¹Ù‚Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø¨ÙƒØ©\n",
    "# Ù…Ù„Ø§Ø­Ø¸Ø©: nearest_nodes ÙŠØ£Ø®Ø° X=lon, Y=lat (OSMnx v2 User Reference)\n",
    "# https://osmnx.readthedocs.io/en/stable/user-reference.html#osmnx.distance.nearest_nodes\n",
    "bin_nodes = [ox.distance.nearest_nodes(G_cc, lon, lat) for (lat, lon) in snapped_pts]\n",
    "# Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø§Øª ÙˆØ§Ù„ØªØ£ÙƒØ¯ Ø£Ù†Ù‡Ø§ Ø¶Ù…Ù† G_cc\n",
    "bin_nodes = list(dict.fromkeys([n for n in bin_nodes if n in G_cc.nodes]))\n",
    "print(f\"âœ… Points after mapping to unique reachable nodes: {len(bin_nodes)}\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# Ø§Ø®ØªÙŠØ§Ø± Ø¯ÙŠØ¨Ùˆ Ø°ÙƒÙŠ ÙŠØ²ÙŠØ¯ Ø§Ù„ÙˆØµÙˆÙ„ Ø§Ù„Ù…ÙˆØ¬Ù‘Ù‡\n",
    "# ------------------------------------------\n",
    "# Ù…Ø±Ø´Ø­ Ù…Ø±ÙƒØ²ÙŠ: Ø£Ù‚Ø±Ø¨ Ø¹Ù‚Ø¯Ø© Ø¥Ù„Ù‰ Ù…Ø±ÙƒØ² bbox Ù„Ù„Ø´Ø¨ÙƒØ©\n",
    "xs = np.array([G_cc.nodes[n][\"x\"] for n in G_cc.nodes()])\n",
    "ys = np.array([G_cc.nodes[n][\"y\"] for n in G_cc.nodes()])\n",
    "cx, cy = float(xs.mean()), float(ys.mean())\n",
    "center_node = ox.distance.nearest_nodes(G_cc, cx, cy)\n",
    "\n",
    "# Ù…Ø±Ø´Ø­ closeness Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ø±Ø§Ù ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬Ù‡ (Ø³Ø±ÙŠØ¹ ÙˆÙ…Ø¤Ø«Ø±)\n",
    "close = nx.closeness_centrality(Gud, distance=\"length\")\n",
    "topk = [n for n,_ in sorted(close.items(), key=lambda kv: kv[1], reverse=True)[:5]]\n",
    "\n",
    "# 10 Ù…ØµØ¨Ø§Øª (bins) ÙƒÙ…Ø±Ø´Ø­ÙŠÙ† Ù…ØªÙ†ÙˆØ¹Ø© Ù…ÙƒØ§Ù†ÙŠØ§Ù‹\n",
    "rnd_bins = random.sample(bin_nodes, k=min(10, len(bin_nodes)))\n",
    "\n",
    "candidates = list(dict.fromkeys([center_node] + topk + rnd_bins))\n",
    "\n",
    "@functools.lru_cache(maxsize=200_000)\n",
    "def _dir_time(u, v):\n",
    "    if u == v: return 0.0\n",
    "    try:\n",
    "        return nx.shortest_path_length(G_cc, u, v, weight=\"travel_time\")\n",
    "    except nx.NetworkXNoPath:\n",
    "        return float(\"inf\")\n",
    "\n",
    "def directed_reach_stats(src):\n",
    "    cnt = 0\n",
    "    tsum = 0.0\n",
    "    for n in bin_nodes:\n",
    "        tt = _dir_time(src, n)\n",
    "        if math.isfinite(tt):\n",
    "            cnt += 1\n",
    "            tsum += tt\n",
    "    return cnt, tsum\n",
    "\n",
    "scores = [(n,)+directed_reach_stats(n) for n in candidates]\n",
    "# Ø£ÙØ¶Ù„: Ø£ÙƒØ¨Ø± ÙˆØµÙˆÙ„ Ù…ÙˆØ¬Ù‘Ù‡ Ø«Ù… Ø£Ù‚Ù„ Ù…Ø¬Ù…ÙˆØ¹ Ø²Ù…Ù† Ù„Ù„ÙˆØµÙˆÙ„\n",
    "best_node, best_reach, best_sum = sorted(scores, key=lambda t: (-t[1], t[2]))[0]\n",
    "\n",
    "depot_node = best_node\n",
    "DEPOT_LAT, DEPOT_LON = G_cc.nodes[depot_node][\"y\"], G_cc.nodes[depot_node][\"x\"]\n",
    "print(\"ğŸ” Depot candidates (node:reach,sum_s):\",\n",
    "      \", \".join([f\"{n}:{r},{int(s)}\" for n, r, s in scores]))\n",
    "print(f\"âœ… Picked depot node: {depot_node}  (directed reach {best_reach}/{len(bin_nodes)})\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„ØªÙˆØ¬ÙŠÙ‡\n",
    "# ------------------------------------------\n",
    "@functools.lru_cache(maxsize=100_000)\n",
    "def travel_time_sec(u, v):\n",
    "    \"\"\"Ø£Ù‚ØµØ± Ø²Ù…Ù† Ø¨ÙŠÙ† Ø¹Ù‚Ø¯ØªÙŠÙ† (Ø«ÙˆØ§Ù†ÙŠ) Ø¨Ù…Ø±Ø§Ø¹Ø§Ø© Ø§Ù„Ø§ØªØ¬Ø§Ù‡ØŒ Ù…Ø¹ Ø§Ø­ØªÙŠØ§Ø·ÙŠ ØºÙŠØ± Ù…ÙˆØ¬Ù‘Ù‡.\"\"\"\n",
    "    if u == v:\n",
    "        return 0.0\n",
    "    try:\n",
    "        return nx.shortest_path_length(G_cc, u, v, weight=\"travel_time\")\n",
    "    except nx.NetworkXNoPath:\n",
    "        try:\n",
    "            # fallback ØºÙŠØ± Ù…ÙˆØ¬Ù‘Ù‡ Ø¨Ø·ÙˆÙ„/Ø³Ø±Ø¹Ø© ØªÙ‚Ø±ÙŠØ¨ÙŠØ©\n",
    "            L = nx.shortest_path_length(Gud, u, v, weight=\"length\")\n",
    "            return L / fallback_mps\n",
    "        except Exception:\n",
    "            return float(\"inf\")\n",
    "\n",
    "@functools.lru_cache(maxsize=100_000)\n",
    "def route_nodes(u, v):\n",
    "    \"\"\"Ø§Ù„Ø¹Ù‚Ø¯ Ø§Ù„Ù…ÙƒÙˆÙ‘Ù†Ø© Ù„Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø£Ù‚ØµØ± (Ù„Ù„Ø±Ø³Ù…/Ø§Ù„Ø­Ø³Ø§Ø¨).\"\"\"\n",
    "    if u == v:\n",
    "        return [u]\n",
    "    # Ø­Ø§ÙˆÙ„ Ù…ÙˆØ¬Ù‘Ù‡ Ø£ÙˆÙ„Ø§Ù‹\n",
    "    try:\n",
    "        return nx.shortest_path(G_cc, u, v, weight=\"travel_time\")\n",
    "    except nx.NetworkXNoPath:\n",
    "        try:\n",
    "            return nx.shortest_path(Gud, u, v, weight=\"length\")\n",
    "        except Exception:\n",
    "            return []\n",
    "\n",
    "def path_stats(u, v):\n",
    "    \"\"\"Ø²Ù…Ù†/Ù…Ø³Ø§ÙØ© Ù„Ù…Ù‚Ø·Ø¹ ÙˆØ§Ø­Ø¯ Ø¹Ø¨Ø± route_to_gdf (v2).\"\"\"\n",
    "    nodes = route_nodes(u, v)\n",
    "    if len(nodes) < 2:\n",
    "        return 0.0, 0.0\n",
    "    try:\n",
    "        # https://osmnx.readthedocs.io/en/stable/internals-reference.html#osmnx.routing.route_to_gdf\n",
    "        gdf = ox.routing.route_to_gdf(G_cc, nodes, weight=\"travel_time\")\n",
    "        sec = float(gdf[\"travel_time\"].sum()) if \"travel_time\" in gdf else 0.0\n",
    "        meters = float(gdf[\"length\"].sum()) if \"length\" in gdf else 0.0\n",
    "        return sec, meters\n",
    "    except Exception:\n",
    "        # Ø§Ø­ØªÙŠØ§Ø·ÙŠ: Ø§Ø¬Ù…Ø¹ ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ù…Ù† Ø§Ù„Ø­ÙˆØ§Ù\n",
    "        sec_total, m_total = 0.0, 0.0\n",
    "        for a, b in zip(nodes[:-1], nodes[1:]):\n",
    "            try:\n",
    "                # Ø®Ø° Ø£Ù‚ØµØ± Ø­Ø§ÙØ© Ø¨ÙŠÙ† a,b\n",
    "                k, d = min(G_cc[a][b].items(), key=lambda kv: kv[1].get(\"length\", float(\"inf\")))\n",
    "            except Exception:\n",
    "                continue\n",
    "            sec_total += float(d.get(\"travel_time\", 0.0))\n",
    "            m_total   += float(d.get(\"length\", 0.0))\n",
    "        return sec_total, m_total\n",
    "\n",
    "# ------------------------------------------\n",
    "# ØªÙ‚Ø³ÙŠÙ… Ø¨Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø²Ø§ÙˆÙŠ (Sweep) + Ù…ÙˆØ§Ø²Ù†Ø© Ø¨Ø³ÙŠØ·Ø©\n",
    "# ------------------------------------------\n",
    "dep_y, dep_x = G_cc.nodes[depot_node][\"y\"], G_cc.nodes[depot_node][\"x\"]\n",
    "def angle_of(n):\n",
    "    y, x = G_cc.nodes[n][\"y\"], G_cc.nodes[n][\"x\"]\n",
    "    return math.atan2(y - dep_y, x - dep_x)\n",
    "\n",
    "ordered = sorted(bin_nodes, key=angle_of)\n",
    "buckets = [ordered[i::V] for i in range(V)]\n",
    "\n",
    "def rebalance_by_time(buckets, rounds=10):\n",
    "    for _ in range(rounds):\n",
    "        loads = [sum(travel_time_sec(depot_node, n) for n in b) for b in buckets]\n",
    "        worst, best = int(np.argmax(loads)), int(np.argmin(loads))\n",
    "        if not buckets[worst]:\n",
    "            break\n",
    "        moved = buckets[worst].pop()  # Ø¢Ø®Ø± Ø¹Ù†ØµØ± (Ù‚Ø±Ù‘Ø¨ Ù…Ù† Ø·Ø±Ù Ø§Ù„Ù‚Ø·Ø§Ø¹)\n",
    "        buckets[best].append(moved)\n",
    "    return buckets\n",
    "\n",
    "buckets = rebalance_by_time(buckets, rounds=12)\n",
    "\n",
    "# ------------------------------------------\n",
    "# Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª (NN) + ØªØ­Ø³ÙŠÙ† 2-opt\n",
    "# ------------------------------------------\n",
    "service_time_sec = {n: random.uniform(*SERVICE_TIME_RANGE) for n in bin_nodes}\n",
    "\n",
    "def route_nn(start, targets):\n",
    "    unvisited = set(targets)\n",
    "    seq = [start]\n",
    "    cur = start\n",
    "    while unvisited:\n",
    "        nxt = min(unvisited, key=lambda n: travel_time_sec(cur, n))\n",
    "        if math.isinf(travel_time_sec(cur, nxt)):\n",
    "            unvisited.remove(nxt)\n",
    "            continue\n",
    "        seq.append(nxt)\n",
    "        cur = nxt\n",
    "        unvisited.remove(nxt)\n",
    "    seq.append(start)\n",
    "    return seq\n",
    "\n",
    "def two_opt(start, stops, iters=MAX_2OPT_ITERS):\n",
    "    if len(stops) < 3:\n",
    "        return stops\n",
    "    best = stops[:]\n",
    "    def cost(path):\n",
    "        return sum(travel_time_sec(a, b) for a, b in zip([start]+path, path+[start]))\n",
    "    best_cost = cost(best)\n",
    "    for _ in range(iters):\n",
    "        improved = False\n",
    "        for i in range(len(best)-1):\n",
    "            for j in range(i+2, len(best)):\n",
    "                new = best[:i] + best[i:j][::-1] + best[j:]\n",
    "                c = cost(new)\n",
    "                if c < best_cost - 1e-6:\n",
    "                    best, best_cost = new, c\n",
    "                    improved = True\n",
    "                    break\n",
    "            if improved: break\n",
    "        if not improved:\n",
    "            break\n",
    "    return best\n",
    "\n",
    "vehicle_routes = []\n",
    "for g in buckets:\n",
    "    seq = route_nn(depot_node, g)\n",
    "    stops = seq[1:-1]\n",
    "    if USE_2OPT and len(stops) > 2:\n",
    "        stops = two_opt(depot_node, stops, MAX_2OPT_ITERS)\n",
    "    route = [depot_node] + stops + [depot_node]\n",
    "    vehicle_routes.append(route)\n",
    "\n",
    "# ------------------------------------------\n",
    "# ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
    "# ------------------------------------------\n",
    "reports = []\n",
    "for i, seq in enumerate(vehicle_routes, 1):\n",
    "    travel_sec, dist_m = 0.0, 0.0\n",
    "    for a, b in zip(seq[:-1], seq[1:]):\n",
    "        t, l = path_stats(a, b)\n",
    "        travel_sec += t\n",
    "        dist_m += l\n",
    "    unique_stops = list(dict.fromkeys(seq[1:-1]))\n",
    "    service_sec = sum(service_time_sec[n] for n in unique_stops)\n",
    "    reports.append({\n",
    "        \"vehicle\": i,\n",
    "        \"stops\": len(unique_stops),\n",
    "        \"travel_min\": travel_sec/60.0,\n",
    "        \"service_min\": service_sec/60.0,\n",
    "        \"total_min\": (travel_sec+service_sec)/60.0,\n",
    "        \"dist_km\": dist_m/1000.0,\n",
    "        \"seq\": seq\n",
    "    })\n",
    "\n",
    "# ------------------------------------------\n",
    "# Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©\n",
    "# ------------------------------------------\n",
    "print(\"\\n=== Results ===\")\n",
    "if reports:\n",
    "    total_time = sum(r[\"total_min\"] for r in reports)\n",
    "    max_time = max(r[\"total_min\"] for r in reports)\n",
    "    for r in reports:\n",
    "        print(f\"ğŸšš Vehicle {r['vehicle']:>2}: {r['stops']:>3} stops | \"\n",
    "              f\"travel={r['travel_min']:.1f}m | service={r['service_min']:.1f}m | \"\n",
    "              f\"total={r['total_min']:.1f}m | dist={r['dist_km']:.2f} km\")\n",
    "    covered_nodes = set()\n",
    "    for r in reports:\n",
    "        covered_nodes.update(r[\"seq\"][1:-1])\n",
    "    print(f\"\\nCoverage: {len(covered_nodes)}/{len(bin_nodes)} points reached\")\n",
    "    print(f\"Total time (all): {total_time/60.0:.1f} hours\")\n",
    "    print(f\"Longest vehicle: {max_time/60.0:.1f} hours\")\n",
    "else:\n",
    "    print(\"No routes produced.\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# Ø±Ø³Ù…: Ø®Ø±ÙŠØ·Ø© ØªÙØ§Ø¹Ù„ÙŠØ© (GeoPandas.explore) + Ø¨Ø¯Ø§Ø¦Ù„\n",
    "# Ù…Ù„Ø§Ø­Ø¸Ø©: ÙˆØ­Ø¯Ø© folium ÙÙŠ OSMnx Ø£ÙØ²ÙŠÙ„Øª ÙÙŠ v2 â€” Ø§Ø³ØªØ®Ø¯Ù… .explore Ù…Ù† GeoPandas\n",
    "# https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.explore.html\n",
    "# ------------------------------------------\n",
    "out_map = \"vrp_map.html\"\n",
    "try:\n",
    "    if _HAS_GPD:\n",
    "        edges_gdf = ox.graph_to_gdfs(G_cc, nodes=False)\n",
    "        m = edges_gdf.explore(style_kwds={\"opacity\": 0.6, \"weight\": 2})\n",
    "\n",
    "        if _HAS_FOLIUM:\n",
    "            # Ø¯ÙŠØ¨Ùˆ\n",
    "            folium.CircleMarker(location=[DEPOT_LAT, DEPOT_LON],\n",
    "                                radius=6, color=\"green\", fill=True).add_to(m)\n",
    "            # Ù†Ù‚Ø§Ø· Ø§Ù„Ø®Ø¯Ù…Ø© (Ø¨Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£Ø­Ù…Ø±)\n",
    "            for n in bin_nodes:\n",
    "                y, x = G_cc.nodes[n][\"y\"], G_cc.nodes[n][\"x\"]\n",
    "                folium.CircleMarker(location=[y, x], radius=2, color=\"red\", fill=True).add_to(m)\n",
    "            # Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø±ÙƒØ¨Ø§Øª Ø¨Ø£Ù„ÙˆØ§Ù† Ù…Ø®ØªÙ„ÙØ©\n",
    "            colors = [\"#10b981\", \"#3b82f6\", \"#f59e0b\", \"#ef4444\", \"#8b5cf6\", \"#14b8a6\"]\n",
    "            for i, r in enumerate(reports):\n",
    "                col = colors[i % len(colors)]\n",
    "                seq = r[\"seq\"]\n",
    "                for a, b in zip(seq[:-1], seq[1:]):\n",
    "                    nodes = route_nodes(a, b)\n",
    "                    if len(nodes) >= 2:\n",
    "                        coords = [(G_cc.nodes[z][\"y\"], G_cc.nodes[z][\"x\"]) for z in nodes]\n",
    "                        folium.PolyLine(coords, weight=3, opacity=0.9, color=col).add_to(m)\n",
    "        m.save(out_map)\n",
    "        print(f\"ğŸ—ºï¸ Saved interactive map: {out_map}\")\n",
    "    else:\n",
    "        raise ImportError(\"GeoPandas not available\")\n",
    "except Exception as e:\n",
    "    print(\"â„¹ï¸ Interactive map not generated (\", str(e), \"). Falling back to static PNG...\")\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = ox.plot_graph(G_cc, show=False, close=False, node_size=0,\n",
    "                            edge_color=\"#b8b8b8\", edge_alpha=0.6, bgcolor=\"white\", figsize=(7,7))\n",
    "    # Ù†Ù‚Ø§Ø·\n",
    "    lats = [G_cc.nodes[n][\"y\"] for n in bin_nodes]\n",
    "    lons = [G_cc.nodes[n][\"x\"] for n in bin_nodes]\n",
    "    ax.scatter(lons, lats, s=10, c=\"red\", zorder=5, label=\"Bins\")\n",
    "    ax.scatter(DEPOT_LON, DEPOT_LAT, s=60, c=\"lime\", zorder=6, label=\"Depot\")\n",
    "\n",
    "    # Ù…Ø³Ø§Ø±Ø§Øª\n",
    "    colors = [\"#10b981\", \"#3b82f6\", \"#f59e0b\", \"#ef4444\", \"#8b5cf6\", \"#14b8a6\"]\n",
    "    for i, r in enumerate(reports):\n",
    "        col = colors[i % len(colors)]\n",
    "        seq = r[\"seq\"]\n",
    "        for a, b in zip(seq[:-1], seq[1:]):\n",
    "            nodes = route_nodes(a, b)\n",
    "            if len(nodes) > 1:\n",
    "                xs = [G_cc.nodes[z][\"x\"] for z in nodes]\n",
    "                ys = [G_cc.nodes[z][\"y\"] for z in nodes]\n",
    "                ax.plot(xs, ys, lw=2.5, alpha=0.9, color=col)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"optimized_vrp.png\", dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f9003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
